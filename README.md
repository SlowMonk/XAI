# XAI

* paper review
* code implementation 

### TODO 

##### Attribution

- [ ] Implement 'DeconvNet'

- [X] Implement 'Saliency'
- [ ] Implement 'Vanilla Saliency'

- [ ] Implement 'Vanila Backpropogation(VBP)'
- [ ] Implement 'Input x Backpropogation'
- [ ] Implement 'LRP'
- [ ] Implement 'DeepLIFT'
- [ ] Implement 'Guided Backpropogation(GB)'

- [x] Implement 'CAM'
- [x] Implement 'GradCam'
- [ ] Implement 'GradCam++'
- [ ] Implement 'Guided Grad Cam'
- [X] Implement 'SmoothGrad'
- [X] Implement 'VarGrad'
- [X] Implement 'Gradient * Input'
- [X] Implement 'Integrated Gradients'
- [ ] Implement 'Guided Gradients'


- [ ] Implement 'LIME'
- [ ] Implement 'Blackbox perturbation'

##### Evaluation

- [X] Implement 'Coherence'
- [X] Implement 'Class Sensitivity'
- [ ] Implement 'Selectivity'
- [ ] Implement 'Roar/Kar'



##### Other reading 

* Deep CLosed-Form Subspace Clustering
* NL-LinkNet: Toward Lighter but More Accurate Road Extraction With Non-Local Operations
* [Why are Saliency Maps Noisy? Cause of and Solution to Noisy Saliency Maps 2019](https://arxiv.org/pdf/1902.04893.pdf)
  

* [SmoothGrad-2017](https://arxiv.org/pdf/1706.03825.pdf)
* [vargrad Noise adding methods of Saliency maps as Series of Higher order Partial Derivative-2018](https://arxiv.org/pdf/1806.03000.pdf)
* [Sanity Checks for Saliency Maps-2018](https://arxiv.org/pdf/1810.03292.pdf)
* [integrated gradients Axiomatic Attribution for Deep Networks-2017 Jun](https://arxiv.org/pdf/1703.01365.pdf)
* [Epsilon-LRP Layer-wise Relevance Propagation for Deep
Neural Network Architectures-2015 ](http://iphome.hhi.de/samek/pdf/BinICISA16.pdf)
* [DeepLIFT Learning Important Features Through Propagating Activation Differences
-2017](https://arxiv.org/abs/1704.02685)
* [Zeiler, Matthew D., and Rob Fergus. "Visualizing and understanding convolutional networks."
ECCV. 2014.]()
* [Fong, Ruth C., and Andrea Vedaldi. "Interpretable explanations of black boxes by meaningful
perturbation." CVPR. 2017.]()
* [Zhang, Quanshi, Ying Nian Wu, and Song-Chun Zhu. "Interpretable convolutional neural
networks." CVPR. 2018.]()
* [Wagner, Jorg, et al. "Interpretable and Fine-Grained Visual Explanations for Convolutional
Neural Networks." CVPR. 2019.]()
* []()
* []()



##### Gradient methods:
* [Saliency(Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps 2014 Apr)](https://arxiv.org/abs/1312.6034)
* [Guided backpropogation(Striving for Simplicity: The All Convolutional Net 2015)](https://arxiv.org/abs/1412.6806)
* [Grad cam(Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization 2017)](https://arxiv.org/abs/1610.02391)
* [Guided gradcam(Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization 2017)](https://arxiv.org/abs/1610.02391)
* [Integrated gradients(Axiomatic Attribution for Deep Networks 2017 Jun)](https://arxiv.org/abs/1703.01365)
* [Layer-wise relevance propagation](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140)
  
 
##### Model-independent methods:

* [Prediction difference(Visualizing Deep Neural Network Decisions: Prediction Difference Analysis 2017 Feb)](https://arxiv.org/abs/1702.04595)
* [Basic graying out (Visualizing and Understanding Convolutional Networks 2013 Nov)](https://arxiv.org/abs/1311.2901)
* [LIME("Why Should I Trust You?": Explaining the Predictions of Any Classifier 2016)](https://arxiv.org/abs/1602.04938)

##### Evaluation methods 

* [Ancona, Marco, et al. "Towards better understanding of gradient-based attribution methods for
deep neural networks." ICLR. 2018. ]()
* [Hooker, Sara, et al. "Evaluating feature importance estimates." ICML Workshop. 2018.]()
* [Nie, Weili, Yang Zhang, and Ankit Patel. "A theoretical explanation for perplexing behaviors of
backpropagation-based visualizations." ICML. 2018.]()
* [Adebayo, Julius, et al. "Sanity checks for saliency maps." NIPS. 2018.]()
* [Yang, Mengjiao, and Been Kim. "BIM: Towards Quantitative Evaluation of Interpretability
Methods with Ground Truth." arXiv preprint arXiv:1907.09701 (2019).]()
* []()
* []()



